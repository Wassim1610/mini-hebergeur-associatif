# 06 — K3s : création des VMs + cluster Kubernetes léger + Traefik

Objectif : créer 3 VMs sur Proxmox (réseau **VLAN 12**), puis déployer 
un cluster **K3s** (1 server + 2 agents).  
Traefik (Ingress) sera utilisé comme **reverse proxy** du projet.

> VMs (VLAN 12 / 10.0.12.8/29)  
> - VM1 : `k3s-server`  → `10.0.12.11`  
> - VM2 : `k3s-worker-1` → `10.0.12.12`  
> - VM3 : `k3s-worker-2` → `10.0.12.13`  
> - Gateway (pfSense VLAN12) → `10.0.12.14`

---

## 1) Créer les VMs K3s dans Proxmox

### 1.1 Recommandations (dimensionnement)
Pour un cluster étudiant stable :
- **k3s-server** : 2 vCPU / 2–4 Go RAM / 20 Go disque
- **workers** : 2 vCPU / 2–4 Go RAM / 20 Go disque

Stockage :
- si Ceph (RBD) est en place : utiliser le stockage `ceph-vm` (chapitre 
05).

Réseau :
- connecter chaque VM sur `vmbr0` en **VLAN tag 12** (réseau 
VM/Services).

### 1.2 Paramètres Proxmox (à respecter)
Pour chaque VM :
- BIOS/UEFI : par défaut (selon ISO)
- Carte réseau : VirtIO (recommandé)
- Disque : VirtIO SCSI (recommandé)
- Boot : ISO Ubuntu/Debian Server (au choix, mais identique sur les 3 
VMs)

> Bon réflexe : nommer les VMs dès la création (`k3s-server`, etc.).  
> Le nom sera repris dans les commandes et la doc.

---

## 2) Configuration IP statique (dans chaque VM)

### 2.1 k3s-server (10.0.12.11/29)
IP : `10.0.12.11/29`  
Gateway : `10.0.12.14`  
DNS : pfSense (si configuré) ou `1.1.1.1` / `8.8.8.8`

### 2.2 k3s-worker-1 (10.0.12.12/29)
IP : `10.0.12.12/29`  
Gateway : `10.0.12.14`

### 2.3 k3s-worker-2 (10.0.12.13/29)
IP : `10.0.12.13/29`  
Gateway : `10.0.12.14`

> La méthode exacte dépend de l’OS :  
> - Ubuntu Server : Netplan  
> - Debian : /etc/network/interfaces ou NetworkManager  
> L’objectif est simple : les 3 VMs doivent se ping entre elles et 
accéder aux dépôts (si autorisé par pfSense).

### 2.4 Vérification réseau minimale (sur chaque VM)
```bash
ip a
ip route
ping -c 2 10.0.12.14
ping -c 2 10.0.12.11
ping -c 2 10.0.12.12
ping -c 2 10.0.12.13
```

Résultat attendu :
- ping OK vers la gateway et entre VMs.

---

## 3) Pré-requis système avant K3s (sur les 3 VMs)

### 3.1 Mise à jour + paquets utiles
Sur chaque VM :
```bash
sudo apt update
sudo apt upgrade -y
sudo apt install -y curl ca-certificates gnupg qemu-guest-agent
sudo systemctl enable --now qemu-guest-agent
```

### 3.2 Désactiver le swap (recommandé Kubernetes)
Vérifier :
```bash
swapon --show
```

Si du swap existe :
```bash
sudo swapoff -a
sudo sed -i.bak '/\sswap\s/s/^/#/' /etc/fstab
```

### 3.3 Activer les modules kernel nécessaires
Sur chaque VM :
```bash
sudo modprobe overlay
sudo modprobe br_netfilter

cat <<'EOF' | sudo tee /etc/modules-load.d/k3s.conf
overlay
br_netfilter
EOF

cat <<'EOF' | sudo tee /etc/sysctl.d/k3s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

sudo sysctl --system
```

---

## 4) Installation de K3s (server)

K3s utilise **containerd** en runtime (intégré), ce qui est adapté aux 
ressources limitées.  
Docker reste utile pour **builder** des images (chapitre 07 : registry), 
mais n’est pas requis sur les nœuds K3s.

### 4.1 Installer le server sur `k3s-server` (10.0.12.11)
Sur la VM `k3s-server` :

```bash
curl -sfL https://get.k3s.io |   INSTALL_K3S_EXEC="server --node-ip 
10.0.12.11 --advertise-address 10.0.12.11 --write-kubeconfig-mode 644"   
sh -
```

### 4.2 Vérifier l’état du service
```bash
sudo systemctl status k3s --no-pager
```

### 4.3 Vérifier Kubernetes (sur le server)
```bash
sudo kubectl get nodes -o wide
sudo kubectl get pods -A
```

Résultat attendu :
- le node `k3s-server` apparaît en `Ready`
- les pods système (kube-system) démarrent

---

## 5) Récupérer le token (server) pour joindre les agents

Sur `k3s-server` :
```bash
sudo cat /var/lib/rancher/k3s/server/node-token
```

Copier la valeur (token) : elle servira pour les workers.

---

## 6) Installation de K3s (agents / workers)

Sur `k3s-worker-1` (10.0.12.12) :

```bash
curl -sfL https://get.k3s.io |   K3S_URL="https://10.0.12.11:6443"   
K3S_TOKEN="COLLER_LE_TOKEN_ICI"   INSTALL_K3S_EXEC="agent --node-ip 
10.0.12.12"   sh -
```

Sur `k3s-worker-2` (10.0.12.13) :

```bash
curl -sfL https://get.k3s.io |   K3S_URL="https://10.0.12.11:6443"   
K3S_TOKEN="COLLER_LE_TOKEN_ICI"   INSTALL_K3S_EXEC="agent --node-ip 
10.0.12.13"   sh -
```

---

## 7) Vérification du cluster (sur le server)

Sur `k3s-server` :

```bash
sudo kubectl get nodes -o wide
```

Résultat attendu :
- `k3s-server` : Ready
- `k3s-worker-1` : Ready
- `k3s-worker-2` : Ready

---

## 8) Traefik (reverse proxy) dans K3s

### 8.1 Ce qu’il faut savoir
Par défaut, K3s installe **Traefik** (Ingress Controller) 
automatiquement.  
Traefik jouera le rôle de **reverse proxy** pour exposer le service Web 
(chapitre 08).

### 8.2 Vérifier Traefik
Sur `k3s-server` :

```bash
sudo kubectl -n kube-system get deploy traefik
sudo kubectl -n kube-system get svc traefik
sudo kubectl -n kube-system get pods -l app.kubernetes.io/name=traefik
```

Résultat attendu :
- deployment traefik présent
- pods traefik running

---

## 9) Contrôles fin de chapitre (checklist)
- [ ] Les 3 VMs sont sur **VLAN 12** et se ping
- [ ] `k3s-server` installé et service `k3s` actif
- [ ] Les 2 workers ont rejoint le cluster
- [ ] `kubectl get nodes` montre 3 nodes `Ready`
- [ ] Traefik est déployé dans `kube-system`

---

## 10) Étape suivante
- **07 — Docker Registry** : construire/publier les images (Docker) et 
disposer d’un point de stockage (registry) propre.  
- **08 — Déploiement de l’application** : déployer Web + BDD sur K3s et 
exposer via Traefik (Ingress).

